{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8757e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "912f4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = 5000 #len(vocab) # 단어 사전(어휘집)의 크기\n",
    "emsize = 200 # 임베딩 차원\n",
    "nhid = 200 # nn.TransformerEncoder 에서 피드포워드 네트워크(feedforward network) 모델의 차원\n",
    "nlayers = 2 # nn.TransformerEncoder 내부의 nn.TransformerEncoderLayer 개수\n",
    "nhead = 2 # 멀티헤드 어텐션(multi-head attention) 모델의 헤드 개수\n",
    "dropout = 0.2 # 드랍아웃(dropout) 값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3302c90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout)\n",
    "d_model = emsize\n",
    "max_len=5000\n",
    "pe = torch.zeros(max_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdbc9e2",
   "metadata": {},
   "source": [
    "### 기본적으로 저 pe라는 텐서를 만드는게 목적\n",
    "- 최초 정의를 max_len으로 하는 이유는 모델 최대크기 사용에서도 유효하길 바래서라는 생각\n",
    "- 여기서 d_model은 embeding의 dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a04a7142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([5000, 200])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(pe)\n",
    "print(pe.shape)\n",
    "print(pe.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7f8aff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8a5f0c",
   "metadata": {},
   "source": [
    "### position\n",
    "- token의 위치정보에 따라 선행 계산된 값을 전달하기 위해서 미리 포지션 matrix를 생성\n",
    "- arange(start, end, type) : range의 torch 버전\n",
    "- unsqueeze(dim) : shape가 [5000]인 애한테 unsqueeze(0)해주면 [1, 5000]이 되고 unsqueeze(1)해주면 [5000, 1]이 되는 식으로 dim에다가 1인 차원을 추가해줌, 참고로 dim이 1인 차원을 모두 날려버리는 squeeze()가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ae6eadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [2.0000e+00],\n",
      "        ...,\n",
      "        [4.9970e+03],\n",
      "        [4.9980e+03],\n",
      "        [4.9990e+03]])\n",
      "torch.Size([5000, 1])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(position)\n",
    "print(position.shape)\n",
    "print(position.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae3b9b",
   "metadata": {},
   "source": [
    "### div_term\n",
    "- 사실 이건그냥 주기다.\n",
    "  - dim마다 같은 값을 더하는게 아니라 주기를 다르게 해서 조금 더 티나게 만들려는듯 굳이 다르게 해야하는가는 잘 모르겠다.\n",
    "  - 참고로 간격이 dim이 원래의 절반이 되게 arange간격을 2로 설정되어있다.\n",
    "    - 나중에 cos랑 sin을 반반씩 섞어서 매핑할거라 반만쓴다.\n",
    "    - 그래서 전체 dim은 짝수여야만 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f1959d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_term = (torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a03d86fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 9.1201e-01, 8.3176e-01, 7.5858e-01, 6.9183e-01, 6.3096e-01,\n",
      "         5.7544e-01, 5.2481e-01, 4.7863e-01, 4.3652e-01, 3.9811e-01, 3.6308e-01,\n",
      "         3.3113e-01, 3.0200e-01, 2.7542e-01, 2.5119e-01, 2.2909e-01, 2.0893e-01,\n",
      "         1.9055e-01, 1.7378e-01, 1.5849e-01, 1.4454e-01, 1.3183e-01, 1.2023e-01,\n",
      "         1.0965e-01, 1.0000e-01, 9.1201e-02, 8.3176e-02, 7.5858e-02, 6.9183e-02,\n",
      "         6.3096e-02, 5.7544e-02, 5.2481e-02, 4.7863e-02, 4.3652e-02, 3.9811e-02,\n",
      "         3.6308e-02, 3.3113e-02, 3.0200e-02, 2.7542e-02, 2.5119e-02, 2.2909e-02,\n",
      "         2.0893e-02, 1.9055e-02, 1.7378e-02, 1.5849e-02, 1.4454e-02, 1.3183e-02,\n",
      "         1.2023e-02, 1.0965e-02, 1.0000e-02, 9.1201e-03, 8.3176e-03, 7.5858e-03,\n",
      "         6.9183e-03, 6.3096e-03, 5.7544e-03, 5.2481e-03, 4.7863e-03, 4.3652e-03,\n",
      "         3.9811e-03, 3.6308e-03, 3.3113e-03, 3.0200e-03, 2.7542e-03, 2.5119e-03,\n",
      "         2.2909e-03, 2.0893e-03, 1.9055e-03, 1.7378e-03, 1.5849e-03, 1.4454e-03,\n",
      "         1.3183e-03, 1.2023e-03, 1.0965e-03, 1.0000e-03, 9.1201e-04, 8.3176e-04,\n",
      "         7.5858e-04, 6.9183e-04, 6.3096e-04, 5.7544e-04, 5.2481e-04, 4.7863e-04,\n",
      "         4.3652e-04, 3.9811e-04, 3.6308e-04, 3.3113e-04, 3.0200e-04, 2.7542e-04,\n",
      "         2.5119e-04, 2.2909e-04, 2.0893e-04, 1.9055e-04, 1.7378e-04, 1.5849e-04,\n",
      "         1.4454e-04, 1.3183e-04, 1.2023e-04, 1.0965e-04]])\n",
      "torch.Size([1, 100])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(div_term)\n",
    "print(div_term.shape)\n",
    "print(div_term.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0402c644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [1.0000e+00, 9.1201e-01, 8.3176e-01,  ..., 1.3183e-04, 1.2023e-04,\n",
      "         1.0965e-04],\n",
      "        [2.0000e+00, 1.8240e+00, 1.6635e+00,  ..., 2.6365e-04, 2.4045e-04,\n",
      "         2.1930e-04],\n",
      "        ...,\n",
      "        [4.9970e+03, 4.5573e+03, 4.1563e+03,  ..., 6.5873e-01, 6.0077e-01,\n",
      "         5.4791e-01],\n",
      "        [4.9980e+03, 4.5582e+03, 4.1572e+03,  ..., 6.5886e-01, 6.0089e-01,\n",
      "         5.4802e-01],\n",
      "        [4.9990e+03, 4.5591e+03, 4.1580e+03,  ..., 6.5900e-01, 6.0101e-01,\n",
      "         5.4813e-01]])\n",
      "torch.Size([5000, 100])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = div_term * position \n",
    "print(a)\n",
    "print(a.shape) # 당연한거지만 매트릭스 연산에서 앞에거의 앞의 dim 뒤에꺼의 뒤의 dim이 남는다. 하지만 * 연산은 matrix의 요소별 곱이다\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "72d8b89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000e+00, 9.1201e-01, 8.3176e-01, 7.5858e-01, 6.9183e-01, 6.3096e-01,\n",
      "         5.7544e-01, 5.2481e-01, 4.7863e-01, 4.3652e-01, 3.9811e-01, 3.6308e-01,\n",
      "         3.3113e-01, 3.0200e-01, 2.7542e-01, 2.5119e-01, 2.2909e-01, 2.0893e-01,\n",
      "         1.9055e-01, 1.7378e-01, 1.5849e-01, 1.4454e-01, 1.3183e-01, 1.2023e-01,\n",
      "         1.0965e-01, 1.0000e-01, 9.1201e-02, 8.3176e-02, 7.5858e-02, 6.9183e-02,\n",
      "         6.3096e-02, 5.7544e-02, 5.2481e-02, 4.7863e-02, 4.3652e-02, 3.9811e-02,\n",
      "         3.6308e-02, 3.3113e-02, 3.0200e-02, 2.7542e-02, 2.5119e-02, 2.2909e-02,\n",
      "         2.0893e-02, 1.9055e-02, 1.7378e-02, 1.5849e-02, 1.4454e-02, 1.3183e-02,\n",
      "         1.2023e-02, 1.0965e-02, 1.0000e-02, 9.1201e-03, 8.3176e-03, 7.5858e-03,\n",
      "         6.9183e-03, 6.3096e-03, 5.7544e-03, 5.2481e-03, 4.7863e-03, 4.3652e-03,\n",
      "         3.9811e-03, 3.6308e-03, 3.3113e-03, 3.0200e-03, 2.7542e-03, 2.5119e-03,\n",
      "         2.2909e-03, 2.0893e-03, 1.9055e-03, 1.7378e-03, 1.5849e-03, 1.4454e-03,\n",
      "         1.3183e-03, 1.2023e-03, 1.0965e-03, 1.0000e-03, 9.1201e-04, 8.3176e-04,\n",
      "         7.5858e-04, 6.9183e-04, 6.3096e-04, 5.7544e-04, 5.2481e-04, 4.7863e-04,\n",
      "         4.3652e-04, 3.9811e-04, 3.6308e-04, 3.3113e-04, 3.0200e-04, 2.7542e-04,\n",
      "         2.5119e-04, 2.2909e-04, 2.0893e-04, 1.9055e-04, 1.7378e-04, 1.5849e-04,\n",
      "         1.4454e-04, 1.3183e-04, 1.2023e-04, 1.0965e-04],\n",
      "        [1.0000e+00, 9.1201e-01, 8.3176e-01, 7.5858e-01, 6.9183e-01, 6.3096e-01,\n",
      "         5.7544e-01, 5.2481e-01, 4.7863e-01, 4.3652e-01, 3.9811e-01, 3.6308e-01,\n",
      "         3.3113e-01, 3.0200e-01, 2.7542e-01, 2.5119e-01, 2.2909e-01, 2.0893e-01,\n",
      "         1.9055e-01, 1.7378e-01, 1.5849e-01, 1.4454e-01, 1.3183e-01, 1.2023e-01,\n",
      "         1.0965e-01, 1.0000e-01, 9.1201e-02, 8.3176e-02, 7.5858e-02, 6.9183e-02,\n",
      "         6.3096e-02, 5.7544e-02, 5.2481e-02, 4.7863e-02, 4.3652e-02, 3.9811e-02,\n",
      "         3.6308e-02, 3.3113e-02, 3.0200e-02, 2.7542e-02, 2.5119e-02, 2.2909e-02,\n",
      "         2.0893e-02, 1.9055e-02, 1.7378e-02, 1.5849e-02, 1.4454e-02, 1.3183e-02,\n",
      "         1.2023e-02, 1.0965e-02, 1.0000e-02, 9.1201e-03, 8.3176e-03, 7.5858e-03,\n",
      "         6.9183e-03, 6.3096e-03, 5.7544e-03, 5.2481e-03, 4.7863e-03, 4.3652e-03,\n",
      "         3.9811e-03, 3.6308e-03, 3.3113e-03, 3.0200e-03, 2.7542e-03, 2.5119e-03,\n",
      "         2.2909e-03, 2.0893e-03, 1.9055e-03, 1.7378e-03, 1.5849e-03, 1.4454e-03,\n",
      "         1.3183e-03, 1.2023e-03, 1.0965e-03, 1.0000e-03, 9.1201e-04, 8.3176e-04,\n",
      "         7.5858e-04, 6.9183e-04, 6.3096e-04, 5.7544e-04, 5.2481e-04, 4.7863e-04,\n",
      "         4.3652e-04, 3.9811e-04, 3.6308e-04, 3.3113e-04, 3.0200e-04, 2.7542e-04,\n",
      "         2.5119e-04, 2.2909e-04, 2.0893e-04, 1.9055e-04, 1.7378e-04, 1.5849e-04,\n",
      "         1.4454e-04, 1.3183e-04, 1.2023e-04, 1.0965e-04]])\n",
      "torch.Size([2, 100])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "div2 = torch.cat([div_term,div_term], 0)\n",
    "print(div2)\n",
    "print(div2.shape)\n",
    "print(div2.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "680ac7fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (5000) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-30fbf00b093e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiv2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 당연한거지만 매트릭스 연산에서 앞에거의 앞의 dim 뒤에꺼의 뒤의 dim이 남는다. 하지만 * 연산은 matrix의 요소별 곱이다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (5000) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "a = div2 * position \n",
    "print(a)\n",
    "print(a.shape) #\n",
    "print(a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e28717ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  7.9074e-01,  ...,  1.0000e+00,\n",
      "          1.0965e-04,  1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  9.6811e-01,  ...,  1.0000e+00,\n",
      "          2.1930e-04,  1.0000e+00],\n",
      "        ...,\n",
      "        [ 9.5625e-01, -2.9254e-01,  9.0551e-01,  ...,  8.2490e-01,\n",
      "          5.2090e-01,  8.5362e-01],\n",
      "        [ 2.7050e-01, -9.6272e-01,  2.1917e-01,  ...,  8.2483e-01,\n",
      "          5.2100e-01,  8.5356e-01],\n",
      "        [-6.6395e-01, -7.4778e-01, -6.3742e-01,  ...,  8.2476e-01,\n",
      "          5.2109e-01,  8.5350e-01]])\n",
      "torch.Size([5000, 200])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "print(pe)\n",
    "print(pe.shape)\n",
    "print(pe.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1c960",
   "metadata": {},
   "source": [
    "### 아래의 1인 차원을 하나 추가해주는데 이거 의미는 이따 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "06e90008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
      "           0.0000e+00,  1.0000e+00]],\n",
      "\n",
      "        [[ 8.4147e-01,  5.4030e-01,  7.9074e-01,  ...,  1.0000e+00,\n",
      "           1.0965e-04,  1.0000e+00]],\n",
      "\n",
      "        [[ 9.0930e-01, -4.1615e-01,  9.6811e-01,  ...,  1.0000e+00,\n",
      "           2.1930e-04,  1.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 9.5625e-01, -2.9254e-01,  9.0551e-01,  ...,  8.2490e-01,\n",
      "           5.2090e-01,  8.5362e-01]],\n",
      "\n",
      "        [[ 2.7050e-01, -9.6272e-01,  2.1917e-01,  ...,  8.2483e-01,\n",
      "           5.2100e-01,  8.5356e-01]],\n",
      "\n",
      "        [[-6.6395e-01, -7.4778e-01, -6.3742e-01,  ...,  8.2476e-01,\n",
      "           5.2109e-01,  8.5350e-01]]])\n",
      "torch.Size([5000, 1, 200])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "\n",
    "print(pe)\n",
    "print(pe.shape)\n",
    "print(pe.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0004a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
