{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852ef837",
   "metadata": {},
   "source": [
    "## 신경망 모델 구성하기\n",
    "- 대체로 torch.nn에 어지간한거 모두 다 있다. torch의 모든 모듈은 nn.Module의 하위 클래스로 신경망은 여러 layer로 구성된 모듈이다.\n",
    "- 아래의 예제를 보면서 이해해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "060a9a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "31c9ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root = \"/raid/jskim/data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = \"/raid/jskim/data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ade62f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14bf85e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2aa4026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x7f591cbfb130>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b80b870",
   "metadata": {},
   "source": [
    "## 클래스로 정의하기\n",
    "- 신경망 모델을 커다란 하나의 torch.nn.Module 모듈이라 생각하고 만들면 좋다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "85d574e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13088bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea5348d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred  = pred_probab.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4bcb975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.1498, 0.0000, 0.0000, 0.0145, 0.0000, 0.0957, 0.0000,\n",
      "         0.0000]], device='cuda:0', grad_fn=<ReluBackward0>)\n",
      "tensor([[0.0973, 0.0973, 0.1130, 0.0973, 0.0973, 0.0987, 0.0973, 0.1071, 0.0973,\n",
      "         0.0973]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([2], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(logits)\n",
    "print(pred_probab)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6171c12d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0173,  0.0277,  0.0138,  ..., -0.0171, -0.0296,  0.0137],\n",
      "        [ 0.0328,  0.0309,  0.0066,  ...,  0.0320,  0.0254,  0.0251]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([0.0179, 0.0196], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0205,  0.0008,  0.0394,  ..., -0.0281, -0.0010,  0.0294],\n",
      "        [ 0.0252, -0.0190,  0.0364,  ..., -0.0422,  0.0294, -0.0349]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 5.9048e-05, -1.5337e-02], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0437,  0.0023, -0.0342,  ...,  0.0391, -0.0431, -0.0400],\n",
      "        [ 0.0068, -0.0192,  0.0174,  ..., -0.0044,  0.0095,  0.0125]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0375, -0.0062], device='cuda:0', grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab381067",
   "metadata": {},
   "source": [
    "## 하이퍼 파라미터\n",
    "- 모델 최적화 과정을 제어할 수 있는 매개변수로 ephoch, batch size, learning rate가 기본적이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bafdaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be69dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aed6dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)  # 요거 tutorial에 안되있어서 찾아다녔네\n",
    "        # 예측(prediction)과 손실(loss) 계산\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # 역전파\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_Batchs = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) ==y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= batch_size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28a853ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302393  [    0/60000]\n",
      "loss: 2.304411  [ 6400/60000]\n",
      "loss: 2.292821  [12800/60000]\n",
      "loss: 2.286015  [19200/60000]\n",
      "loss: 2.279091  [25600/60000]\n",
      "loss: 2.259528  [32000/60000]\n",
      "loss: 2.258271  [38400/60000]\n",
      "loss: 2.242497  [44800/60000]\n",
      "loss: 2.249248  [51200/60000]\n",
      "loss: 2.212293  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 39.0%, Avg loss: 5.477993 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.247454  [    0/60000]\n",
      "loss: 2.257750  [ 6400/60000]\n",
      "loss: 2.220712  [12800/60000]\n",
      "loss: 2.213846  [19200/60000]\n",
      "loss: 2.189607  [25600/60000]\n",
      "loss: 2.157643  [32000/60000]\n",
      "loss: 2.163785  [38400/60000]\n",
      "loss: 2.134794  [44800/60000]\n",
      "loss: 2.160106  [51200/60000]\n",
      "loss: 2.061599  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.1%, Avg loss: 5.197614 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.155849  [    0/60000]\n",
      "loss: 2.177218  [ 6400/60000]\n",
      "loss: 2.100712  [12800/60000]\n",
      "loss: 2.092805  [19200/60000]\n",
      "loss: 2.030548  [25600/60000]\n",
      "loss: 1.989696  [32000/60000]\n",
      "loss: 1.991818  [38400/60000]\n",
      "loss: 1.942420  [44800/60000]\n",
      "loss: 2.002822  [51200/60000]\n",
      "loss: 1.814172  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 40.3%, Avg loss: 4.723542 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.990633  [    0/60000]\n",
      "loss: 2.022294  [ 6400/60000]\n",
      "loss: 1.927569  [12800/60000]\n",
      "loss: 1.931150  [19200/60000]\n",
      "loss: 1.751411  [25600/60000]\n",
      "loss: 1.767010  [32000/60000]\n",
      "loss: 1.755195  [38400/60000]\n",
      "loss: 1.707721  [44800/60000]\n",
      "loss: 1.814588  [51200/60000]\n",
      "loss: 1.552983  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 47.6%, Avg loss: 4.240928 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.812482  [    0/60000]\n",
      "loss: 1.875145  [ 6400/60000]\n",
      "loss: 1.788279  [12800/60000]\n",
      "loss: 1.799197  [19200/60000]\n",
      "loss: 1.533128  [25600/60000]\n",
      "loss: 1.611973  [32000/60000]\n",
      "loss: 1.576855  [38400/60000]\n",
      "loss: 1.547853  [44800/60000]\n",
      "loss: 1.675813  [51200/60000]\n",
      "loss: 1.386262  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 49.1%, Avg loss: 3.916009 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
