{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1698d7de",
   "metadata": {},
   "source": [
    "# DeiT\n",
    "- Data effecient image transformer\n",
    "  - 이제 최적화와 양자화를 했을 때 어떤 일이 벌어지는지 봐보자: quantized, optimized and non-quantized, non-optimized models\n",
    "  - augmentation, distillation으로 제한된 자원에서 더 좋은 성능을 보이는 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8beb5c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0a0+c3d40fd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import timm\n",
    "import requests\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=3),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "])\n",
    "\n",
    "img = Image.open(requests.get(\"https://raw.githubusercontent.com/pytorch/ios-demo-app/master/HelloWorld/HelloWorld/HelloWorld/image.png\", stream=True).raw)\n",
    "img = transform(img)[None,]\n",
    "out = model(img)\n",
    "clsidx = torch.argmax(out)\n",
    "print(clsidx.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea47b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecursiveScriptModule(\n",
       "  original_name=VisionTransformer\n",
       "  (patch_embed): RecursiveScriptModule(\n",
       "    original_name=PatchEmbed\n",
       "    (proj): RecursiveScriptModule(original_name=Conv2d)\n",
       "    (norm): RecursiveScriptModule(original_name=Identity)\n",
       "  )\n",
       "  (pos_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "  (blocks): RecursiveScriptModule(\n",
       "    original_name=Sequential\n",
       "    (0): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (1): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (2): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (3): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (4): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (5): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (6): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (7): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (8): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (9): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (10): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "    (11): RecursiveScriptModule(\n",
       "      original_name=Block\n",
       "      (norm1): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (attn): RecursiveScriptModule(\n",
       "        original_name=Attention\n",
       "        (qkv): RecursiveScriptModule(original_name=Linear)\n",
       "        (attn_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "        (proj): RecursiveScriptModule(original_name=Linear)\n",
       "        (proj_drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "      (drop_path): RecursiveScriptModule(original_name=Identity)\n",
       "      (norm2): RecursiveScriptModule(original_name=LayerNorm)\n",
       "      (mlp): RecursiveScriptModule(\n",
       "        original_name=Mlp\n",
       "        (fc1): RecursiveScriptModule(original_name=Linear)\n",
       "        (act): RecursiveScriptModule(original_name=GELU)\n",
       "        (fc2): RecursiveScriptModule(original_name=Linear)\n",
       "        (drop): RecursiveScriptModule(original_name=Dropout)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): RecursiveScriptModule(original_name=LayerNorm)\n",
       "  (pre_logits): RecursiveScriptModule(original_name=Identity)\n",
       "  (head): RecursiveScriptModule(original_name=Linear)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
    "model.eval()\n",
    "scripted_model = torch.jit.script(model)\n",
    "scripted_model.save(\"/raid/jskim/data/pretrained/fbdeit_scripted.pt\")\n",
    "scripted_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8424774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서버 추론을 위해 'fbgemm'을, 모바일 추론을 위해 'qnnpack'을 사용해 봅시다.\n",
    "backend = \"fbgemm\" # 이 주피터 노트북에서는 양자화된 모델의 더 느린 추론 속도를 일으키는 qnnpack으로 대체되었습니다.\n",
    "model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "\n",
    "quantized_model = torch.quantization.quantize_dynamic(model, qconfig_spec={torch.nn.Linear}, dtype=torch.qint8)\n",
    "scripted_quantized_model = torch.jit.script(quantized_model)\n",
    "scripted_quantized_model.save(\"/raid/jskim/data/pretrained/fbdeit_scripted_quantized.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33487265",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dtype' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-4a1309ab0b82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscripted_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# scripted_quantized_model.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# out = scripted_quantized_model(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# clsidx = torch.argmax(out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(clsidx.item())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dtype' is not defined"
     ]
    }
   ],
   "source": [
    "out = scripted_model(img).type(torch.float32)\n",
    "# scripted_quantized_model.eval()\n",
    "# out = scripted_quantized_model(img)\n",
    "# clsidx = torch.argmax(out)\n",
    "# print(clsidx.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0db2249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
    "optimized_scripted_quantized_model = optimize_for_mobile(scripted_quantized_model)\n",
    "optimized_scripted_quantized_model.save(\"/raid/jskim/data/pretrained/fbdeit_optimized_scripted_quantized.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "334c63f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269\n"
     ]
    }
   ],
   "source": [
    "out = optimized_scripted_quantized_model(img)\n",
    "clsidx = torch.argmax(out)\n",
    "print(clsidx.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "421d54b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_scripted_quantized_model._save_for_lite_interpreter(\"/raid/jskim/data/pretrained/fbdeit_optimized_scripted_quantized_lite.ptl\")\n",
    "ptl = torch.jit.load(\"/raid/jskim/data/pretrained/fbdeit_optimized_scripted_quantized_lite.ptl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5284fa8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<string>\", line 46, in <foward op>\n            p1m = 1. - p\n            scale = 1. / (float(p1m == 0.) + p1m)\n            res,mask = torch.native_dropout(input, p1m, scale, train)\n                       ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n\n            def backward(grad_output):\nRuntimeError: Train parameter is incorrectly set!\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-0d847948d5bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     out = scripted_model(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprof3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscripted_quantized_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprof4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimized_scripted_quantized_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\nRuntimeError: The following operation failed in the TorchScript interpreter.\nTraceback of TorchScript (most recent call last):\n  File \"<string>\", line 46, in <foward op>\n            p1m = 1. - p\n            scale = 1. / (float(p1m == 0.) + p1m)\n            res,mask = torch.native_dropout(input, p1m, scale, train)\n                       ~~~~~~~~~~~~~~~~~~~~ <--- HERE\n\n            def backward(grad_output):\nRuntimeError: Train parameter is incorrectly set!\n\n"
     ]
    }
   ],
   "source": [
    "with torch.autograd.profiler.profile(use_cuda=False) as prof1:\n",
    "    out = model(img)\n",
    "# with torch.autograd.profiler.profile(use_cuda=False) as prof2:\n",
    "#     out = scripted_model(img)\n",
    "# with torch.autograd.profiler.profile(use_cuda=False) as prof3:\n",
    "#     out = scripted_quantized_model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof4:\n",
    "    out = optimized_scripted_quantized_model(img)\n",
    "with torch.autograd.profiler.profile(use_cuda=False) as prof5:\n",
    "    out = ptl(img)\n",
    "\n",
    "print(\"original model: {:.2f}ms\".format(prof1.self_cpu_time_total/1000))\n",
    "# print(\"scripted model: {:.2f}ms\".format(prof2.self_cpu_time_total/1000))\n",
    "# print(\"scripted & quantized model: {:.2f}ms\".format(prof3.self_cpu_time_total/1000))\n",
    "print(\"scripted & quantized & optimized model: {:.2f}ms\".format(prof4.self_cpu_time_total/1000))\n",
    "print(\"lite model: {:.2f}ms\".format(prof5.self_cpu_time_total/1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7471c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cc75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
